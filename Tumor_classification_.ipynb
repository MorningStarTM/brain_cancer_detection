{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MorningStarTM/brain_cancer_detection/blob/main/Tumor_classification_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dthQn83Z2kPE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import shuffle\n",
        "from glob import glob\n",
        "from tensorflow.keras.layers import*\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import*\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T4teVOGM3Am1"
      },
      "outputs": [],
      "source": [
        "#parameters\n",
        "HEIGHT, WIDTH = 224, 224\n",
        "CHANNEL = 3\n",
        "num_class = 3\n",
        "batch_size = 64\n",
        "class_names = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnnXioXJ3LOH"
      },
      "source": [
        "#Data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ox2OTSKc3Jvb"
      },
      "outputs": [],
      "source": [
        "def load_data(path, split=0.1):\n",
        "    images = shuffle(glob(os.path.join(path, \"*\", \"*.jpg\")))\n",
        "    \n",
        "    #size of split \n",
        "    split_size = int(len(images) * split)\n",
        "\n",
        "    #split the data\n",
        "    train_data, valid_data = train_test_split(images, test_size=split_size, random_state=42)\n",
        "    train_data, test_data = train_test_split(train_data, test_size=split_size, random_state=42)\n",
        "\n",
        "    return train_data, valid_data, test_data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uZB1usmn3SKW"
      },
      "outputs": [],
      "source": [
        "#process the image\n",
        "def process_image(path):\n",
        "    #decode the path\n",
        "    path = path.decode()\n",
        "    #read image\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    #resize the image\n",
        "    image = cv2.resize(image, [224, 224])\n",
        "    #scale the image\n",
        "    image = image / 255.0\n",
        "    #change the data type of image\n",
        "    image = image.astype(np.float32)\n",
        "\n",
        "    #labeling the image\n",
        "    class_name = path.split(\"/\")[-2]\n",
        "    class_idx = class_names.index(class_name)\n",
        "    class_idx = np.array(class_idx, dtype=np.int32)\n",
        "\n",
        "    return image, class_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CyncemCa3Vld"
      },
      "outputs": [],
      "source": [
        "def parse(path):\n",
        "    image, labels = tf.numpy_function(process_image, [path], (tf.float32, tf.int32))\n",
        "    labels = tf.one_hot(labels, 4)\n",
        "    image.set_shape([224, 224, 3])\n",
        "    labels.set_shape(4)\n",
        "  \n",
        "    return image, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Cgt4wkoX3X_V"
      },
      "outputs": [],
      "source": [
        "#tensorflow dataset\n",
        "def tf_dataset(images, batch=8):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images))\n",
        "    dataset = dataset.map(parse)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(2)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLg-_DiG3a88"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dErEI4Hw3ZYl"
      },
      "outputs": [],
      "source": [
        "#input layer\n",
        "inputs = Input(shape=(WIDTH, HEIGHT, CHANNEL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "DKGGELmz3cPs"
      },
      "outputs": [],
      "source": [
        "#convolutional layer\n",
        "conv_x = Conv2D(16, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(inputs)\n",
        "conv_x = BatchNormalization()(conv_x)\n",
        "conv_x = MaxPooling2D((2,2), strides=(2,2))(conv_x)\n",
        "conv_x = Conv2D(16, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "\n",
        "\n",
        "conv_x = Conv2D(32, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "conv_x = BatchNormalization()(conv_x)\n",
        "conv_x = MaxPooling2D((2,2), strides=(1,1))(conv_x)\n",
        "conv_x = Conv2D(32, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "\n",
        "conv_x = Conv2D(64, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "conv_x = BatchNormalization()(conv_x)\n",
        "conv_x = MaxPooling2D((2,2), strides=(2,2))(conv_x)\n",
        "conv_x = Conv2D(64, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "\n",
        "conv_x = Conv2D(128, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "conv_x = BatchNormalization()(conv_x)\n",
        "conv_x = MaxPooling2D((2,2), strides=(2,2))(conv_x)\n",
        "conv_x = Conv2D(128, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "\n",
        "conv_x = Conv2D(256, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "conv_x = BatchNormalization()(conv_x)\n",
        "conv_x = MaxPooling2D((2,2), strides=(2,2))(conv_x)\n",
        "conv_x = Conv2D(256, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "\n",
        "conv_x = Conv2D(512, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "conv_x = BatchNormalization()(conv_x)\n",
        "conv_x = MaxPooling2D((2,2), strides=(2,2))(conv_x)\n",
        "conv_x = Conv2D(512, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "\n",
        "#flatting\n",
        "flatten = Flatten()(conv_x)\n",
        "conv_x = Dense(16, activation='relu')(flatten)\n",
        "con_x = Dropout(0.3)(conv_x)\n",
        "#adding Dense layer with number of class \n",
        "outputs = Dense(4, activation='softmax')(conv_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "tmz0l_yZ4CS9"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10v50j244GQV",
        "outputId": "84a7adad-37c0-4600-c4d1-250435521e07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_92 (Conv2D)          (None, 224, 224, 16)      448       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 224, 224, 16)     64        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d_47 (MaxPoolin  (None, 112, 112, 16)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_93 (Conv2D)          (None, 112, 112, 16)      2320      \n",
            "                                                                 \n",
            " conv2d_94 (Conv2D)          (None, 112, 112, 32)      4640      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 112, 112, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_48 (MaxPoolin  (None, 111, 111, 32)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_95 (Conv2D)          (None, 111, 111, 32)      9248      \n",
            "                                                                 \n",
            " conv2d_96 (Conv2D)          (None, 111, 111, 64)      18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 111, 111, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_49 (MaxPoolin  (None, 55, 55, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_97 (Conv2D)          (None, 55, 55, 64)        36928     \n",
            "                                                                 \n",
            " conv2d_98 (Conv2D)          (None, 55, 55, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 55, 55, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_50 (MaxPoolin  (None, 27, 27, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_99 (Conv2D)          (None, 27, 27, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_100 (Conv2D)         (None, 27, 27, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 27, 27, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_51 (MaxPoolin  (None, 13, 13, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_101 (Conv2D)         (None, 13, 13, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_102 (Conv2D)         (None, 13, 13, 512)       1180160   \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 13, 13, 512)      2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_52 (MaxPoolin  (None, 6, 6, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_103 (Conv2D)         (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 18432)             0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 16)                294928    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,017,764\n",
            "Trainable params: 5,015,748\n",
            "Non-trainable params: 2,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZDtf0KTF4gQT"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-7), loss=\"categorical_crossentropy\", metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vzMUtv7n5aVF"
      },
      "outputs": [],
      "source": [
        "model_file = \"/content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\"\n",
        "csv_file = \"/content/drive/MyDrive/Model CSV/tumor_classification.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Q_sCvQqz42Jl"
      },
      "outputs": [],
      "source": [
        "#initialize the callbakcs\n",
        "callbacks = [\n",
        "    ModelCheckpoint(model_file, verbose=1, save_best_only=True),\n",
        "    CSVLogger(csv_file),\n",
        "    ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, min_lr=1e-7, verbose=1)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aFBRdZoz5YWN"
      },
      "outputs": [],
      "source": [
        "data_path = \"/content/drive/MyDrive/DataSet/brain_cancer/Training\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv-qzDGk7vAt",
        "outputId": "e2075500-fe00-45b5-f87d-8eeb05aca18b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:4586 - Test:573 - Valid:573\n"
          ]
        }
      ],
      "source": [
        "#split the dataset\n",
        "x_train, x_valid, x_test = load_data(data_path)\n",
        "print(f\"Train:{len(x_train)} - Test:{len(x_test)} - Valid:{len(x_valid)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pB8mmzzP756G"
      },
      "outputs": [],
      "source": [
        "#tensor dataset\n",
        "train_df = tf_dataset(x_train)\n",
        "test_df = tf_dataset(x_test)\n",
        "valid_df = tf_dataset(x_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b-OobjVj7-pl",
        "outputId": "fbb7524a-a3a8-4a9b-865c-be1c3bfabbeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.3893 - accuracy: 0.3057\n",
            "Epoch 1: val_loss improved from inf to 1.38973, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 151s 2s/step - loss: 1.3893 - accuracy: 0.3057 - val_loss: 1.3897 - val_accuracy: 0.2705 - lr: 1.0000e-07\n",
            "Epoch 2/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.3526 - accuracy: 0.3094\n",
            "Epoch 2: val_loss improved from 1.38973 to 1.36680, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 454ms/step - loss: 1.3526 - accuracy: 0.3094 - val_loss: 1.3668 - val_accuracy: 0.2670 - lr: 1.0000e-07\n",
            "Epoch 3/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.3266 - accuracy: 0.3092\n",
            "Epoch 3: val_loss improved from 1.36680 to 1.34662, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 456ms/step - loss: 1.3266 - accuracy: 0.3092 - val_loss: 1.3466 - val_accuracy: 0.2565 - lr: 1.0000e-07\n",
            "Epoch 4/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.3049 - accuracy: 0.3105\n",
            "Epoch 4: val_loss improved from 1.34662 to 1.32789, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 459ms/step - loss: 1.3049 - accuracy: 0.3105 - val_loss: 1.3279 - val_accuracy: 0.2618 - lr: 1.0000e-07\n",
            "Epoch 5/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.2853 - accuracy: 0.3199\n",
            "Epoch 5: val_loss improved from 1.32789 to 1.30995, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 460ms/step - loss: 1.2853 - accuracy: 0.3199 - val_loss: 1.3100 - val_accuracy: 0.2670 - lr: 1.0000e-07\n",
            "Epoch 6/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.2669 - accuracy: 0.3314\n",
            "Epoch 6: val_loss improved from 1.30995 to 1.29242, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 34s 472ms/step - loss: 1.2669 - accuracy: 0.3314 - val_loss: 1.2924 - val_accuracy: 0.2914 - lr: 1.0000e-07\n",
            "Epoch 7/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.2496 - accuracy: 0.3528\n",
            "Epoch 7: val_loss improved from 1.29242 to 1.27557, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 455ms/step - loss: 1.2496 - accuracy: 0.3528 - val_loss: 1.2756 - val_accuracy: 0.3002 - lr: 1.0000e-07\n",
            "Epoch 8/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.2330 - accuracy: 0.3857\n",
            "Epoch 8: val_loss improved from 1.27557 to 1.25907, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 453ms/step - loss: 1.2330 - accuracy: 0.3857 - val_loss: 1.2591 - val_accuracy: 0.3298 - lr: 1.0000e-07\n",
            "Epoch 9/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.2175 - accuracy: 0.4202\n",
            "Epoch 9: val_loss improved from 1.25907 to 1.24415, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 449ms/step - loss: 1.2175 - accuracy: 0.4202 - val_loss: 1.2442 - val_accuracy: 0.3839 - lr: 1.0000e-07\n",
            "Epoch 10/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.2031 - accuracy: 0.4542\n",
            "Epoch 10: val_loss improved from 1.24415 to 1.23024, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 445ms/step - loss: 1.2031 - accuracy: 0.4542 - val_loss: 1.2302 - val_accuracy: 0.4136 - lr: 1.0000e-07\n",
            "Epoch 11/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1895 - accuracy: 0.4810\n",
            "Epoch 11: val_loss improved from 1.23024 to 1.21684, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 451ms/step - loss: 1.1895 - accuracy: 0.4810 - val_loss: 1.2168 - val_accuracy: 0.4363 - lr: 1.0000e-07\n",
            "Epoch 12/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1762 - accuracy: 0.5000\n",
            "Epoch 12: val_loss improved from 1.21684 to 1.20387, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 458ms/step - loss: 1.1762 - accuracy: 0.5000 - val_loss: 1.2039 - val_accuracy: 0.4642 - lr: 1.0000e-07\n",
            "Epoch 13/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1635 - accuracy: 0.5172\n",
            "Epoch 13: val_loss improved from 1.20387 to 1.19138, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 445ms/step - loss: 1.1635 - accuracy: 0.5172 - val_loss: 1.1914 - val_accuracy: 0.4817 - lr: 1.0000e-07\n",
            "Epoch 14/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1512 - accuracy: 0.5310\n",
            "Epoch 14: val_loss improved from 1.19138 to 1.17944, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 445ms/step - loss: 1.1512 - accuracy: 0.5310 - val_loss: 1.1794 - val_accuracy: 0.4921 - lr: 1.0000e-07\n",
            "Epoch 15/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1394 - accuracy: 0.5419\n",
            "Epoch 15: val_loss improved from 1.17944 to 1.16780, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 446ms/step - loss: 1.1394 - accuracy: 0.5419 - val_loss: 1.1678 - val_accuracy: 0.5148 - lr: 1.0000e-07\n",
            "Epoch 16/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1282 - accuracy: 0.5523\n",
            "Epoch 16: val_loss improved from 1.16780 to 1.15658, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 454ms/step - loss: 1.1282 - accuracy: 0.5523 - val_loss: 1.1566 - val_accuracy: 0.5201 - lr: 1.0000e-07\n",
            "Epoch 17/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1172 - accuracy: 0.5615\n",
            "Epoch 17: val_loss improved from 1.15658 to 1.14571, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 444ms/step - loss: 1.1172 - accuracy: 0.5615 - val_loss: 1.1457 - val_accuracy: 0.5288 - lr: 1.0000e-07\n",
            "Epoch 18/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1065 - accuracy: 0.5726\n",
            "Epoch 18: val_loss improved from 1.14571 to 1.13505, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 455ms/step - loss: 1.1065 - accuracy: 0.5726 - val_loss: 1.1350 - val_accuracy: 0.5445 - lr: 1.0000e-07\n",
            "Epoch 19/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.0959 - accuracy: 0.5809\n",
            "Epoch 19: val_loss improved from 1.13505 to 1.12454, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 447ms/step - loss: 1.0959 - accuracy: 0.5809 - val_loss: 1.1245 - val_accuracy: 0.5515 - lr: 1.0000e-07\n",
            "Epoch 20/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.0854 - accuracy: 0.5892\n",
            "Epoch 20: val_loss improved from 1.12454 to 1.11431, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 444ms/step - loss: 1.0854 - accuracy: 0.5892 - val_loss: 1.1143 - val_accuracy: 0.5550 - lr: 1.0000e-07\n",
            "Epoch 21/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.0752 - accuracy: 0.5959\n",
            "Epoch 21: val_loss improved from 1.11431 to 1.10432, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 447ms/step - loss: 1.0752 - accuracy: 0.5959 - val_loss: 1.1043 - val_accuracy: 0.5620 - lr: 1.0000e-07\n",
            "Epoch 22/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.0654 - accuracy: 0.6023\n",
            "Epoch 22: val_loss improved from 1.10432 to 1.09453, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 454ms/step - loss: 1.0654 - accuracy: 0.6023 - val_loss: 1.0945 - val_accuracy: 0.5672 - lr: 1.0000e-07\n",
            "Epoch 23/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.0558 - accuracy: 0.6092\n",
            "Epoch 23: val_loss improved from 1.09453 to 1.08500, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 454ms/step - loss: 1.0558 - accuracy: 0.6092 - val_loss: 1.0850 - val_accuracy: 0.5724 - lr: 1.0000e-07\n",
            "Epoch 24/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.0466 - accuracy: 0.6149\n",
            "Epoch 24: val_loss improved from 1.08500 to 1.07573, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 444ms/step - loss: 1.0466 - accuracy: 0.6149 - val_loss: 1.0757 - val_accuracy: 0.5829 - lr: 1.0000e-07\n",
            "Epoch 25/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.0376 - accuracy: 0.6197\n",
            "Epoch 25: val_loss improved from 1.07573 to 1.06678, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 34s 471ms/step - loss: 1.0376 - accuracy: 0.6197 - val_loss: 1.0668 - val_accuracy: 0.5864 - lr: 1.0000e-07\n",
            "Epoch 26/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.0288 - accuracy: 0.6232\n",
            "Epoch 26: val_loss improved from 1.06678 to 1.05813, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 460ms/step - loss: 1.0288 - accuracy: 0.6232 - val_loss: 1.0581 - val_accuracy: 0.5951 - lr: 1.0000e-07\n",
            "Epoch 27/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.0203 - accuracy: 0.6260\n",
            "Epoch 27: val_loss improved from 1.05813 to 1.04969, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 457ms/step - loss: 1.0203 - accuracy: 0.6260 - val_loss: 1.0497 - val_accuracy: 0.6003 - lr: 1.0000e-07\n",
            "Epoch 28/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.0120 - accuracy: 0.6297\n",
            "Epoch 28: val_loss improved from 1.04969 to 1.04152, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 34s 464ms/step - loss: 1.0120 - accuracy: 0.6297 - val_loss: 1.0415 - val_accuracy: 0.6143 - lr: 1.0000e-07\n",
            "Epoch 29/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.0040 - accuracy: 0.6365\n",
            "Epoch 29: val_loss improved from 1.04152 to 1.03360, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 34s 468ms/step - loss: 1.0040 - accuracy: 0.6365 - val_loss: 1.0336 - val_accuracy: 0.6195 - lr: 1.0000e-07\n",
            "Epoch 30/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.9961 - accuracy: 0.6393\n",
            "Epoch 30: val_loss improved from 1.03360 to 1.02584, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 34s 469ms/step - loss: 0.9961 - accuracy: 0.6393 - val_loss: 1.0258 - val_accuracy: 0.6213 - lr: 1.0000e-07\n",
            "Epoch 31/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.9884 - accuracy: 0.6461\n",
            "Epoch 31: val_loss improved from 1.02584 to 1.01828, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 34s 474ms/step - loss: 0.9884 - accuracy: 0.6461 - val_loss: 1.0183 - val_accuracy: 0.6230 - lr: 1.0000e-07\n",
            "Epoch 32/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.9809 - accuracy: 0.6481\n",
            "Epoch 32: val_loss improved from 1.01828 to 1.01093, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 34s 468ms/step - loss: 0.9809 - accuracy: 0.6481 - val_loss: 1.0109 - val_accuracy: 0.6353 - lr: 1.0000e-07\n",
            "Epoch 33/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.9737 - accuracy: 0.6496\n",
            "Epoch 33: val_loss improved from 1.01093 to 1.00377, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 35s 480ms/step - loss: 0.9737 - accuracy: 0.6496 - val_loss: 1.0038 - val_accuracy: 0.6370 - lr: 1.0000e-07\n",
            "Epoch 34/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.9665 - accuracy: 0.6513\n",
            "Epoch 34: val_loss improved from 1.00377 to 0.99680, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 34s 471ms/step - loss: 0.9665 - accuracy: 0.6513 - val_loss: 0.9968 - val_accuracy: 0.6457 - lr: 1.0000e-07\n",
            "Epoch 35/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.9596 - accuracy: 0.6555\n",
            "Epoch 35: val_loss improved from 0.99680 to 0.99002, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 461ms/step - loss: 0.9596 - accuracy: 0.6555 - val_loss: 0.9900 - val_accuracy: 0.6457 - lr: 1.0000e-07\n",
            "Epoch 36/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.9528 - accuracy: 0.6585\n",
            "Epoch 36: val_loss improved from 0.99002 to 0.98339, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 34s 466ms/step - loss: 0.9528 - accuracy: 0.6585 - val_loss: 0.9834 - val_accuracy: 0.6527 - lr: 1.0000e-07\n",
            "Epoch 37/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.9462 - accuracy: 0.6596\n",
            "Epoch 37: val_loss improved from 0.98339 to 0.97696, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 34s 473ms/step - loss: 0.9462 - accuracy: 0.6596 - val_loss: 0.9770 - val_accuracy: 0.6562 - lr: 1.0000e-07\n",
            "Epoch 38/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.9397 - accuracy: 0.6629\n",
            "Epoch 38: val_loss improved from 0.97696 to 0.97069, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 455ms/step - loss: 0.9397 - accuracy: 0.6629 - val_loss: 0.9707 - val_accuracy: 0.6597 - lr: 1.0000e-07\n",
            "Epoch 39/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.9334 - accuracy: 0.6644\n",
            "Epoch 39: val_loss improved from 0.97069 to 0.96454, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 457ms/step - loss: 0.9334 - accuracy: 0.6644 - val_loss: 0.9645 - val_accuracy: 0.6614 - lr: 1.0000e-07\n",
            "Epoch 40/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.9272 - accuracy: 0.6664\n",
            "Epoch 40: val_loss improved from 0.96454 to 0.95852, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 451ms/step - loss: 0.9272 - accuracy: 0.6664 - val_loss: 0.9585 - val_accuracy: 0.6614 - lr: 1.0000e-07\n",
            "Epoch 41/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.9212 - accuracy: 0.6683\n",
            "Epoch 41: val_loss improved from 0.95852 to 0.95262, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 451ms/step - loss: 0.9212 - accuracy: 0.6683 - val_loss: 0.9526 - val_accuracy: 0.6579 - lr: 1.0000e-07\n",
            "Epoch 42/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.9152 - accuracy: 0.6705\n",
            "Epoch 42: val_loss improved from 0.95262 to 0.94685, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 453ms/step - loss: 0.9152 - accuracy: 0.6705 - val_loss: 0.9468 - val_accuracy: 0.6597 - lr: 1.0000e-07\n",
            "Epoch 43/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.9094 - accuracy: 0.6729\n",
            "Epoch 43: val_loss improved from 0.94685 to 0.94122, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 34s 467ms/step - loss: 0.9094 - accuracy: 0.6729 - val_loss: 0.9412 - val_accuracy: 0.6597 - lr: 1.0000e-07\n",
            "Epoch 44/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.9038 - accuracy: 0.6753\n",
            "Epoch 44: val_loss improved from 0.94122 to 0.93570, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 458ms/step - loss: 0.9038 - accuracy: 0.6753 - val_loss: 0.9357 - val_accuracy: 0.6579 - lr: 1.0000e-07\n",
            "Epoch 45/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.8982 - accuracy: 0.6786\n",
            "Epoch 45: val_loss improved from 0.93570 to 0.93029, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 459ms/step - loss: 0.8982 - accuracy: 0.6786 - val_loss: 0.9303 - val_accuracy: 0.6597 - lr: 1.0000e-07\n",
            "Epoch 46/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.8927 - accuracy: 0.6812\n",
            "Epoch 46: val_loss improved from 0.93029 to 0.92498, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 452ms/step - loss: 0.8927 - accuracy: 0.6812 - val_loss: 0.9250 - val_accuracy: 0.6614 - lr: 1.0000e-07\n",
            "Epoch 47/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 0.8874 - accuracy: 0.6838\n",
            "Epoch 47: val_loss improved from 0.92498 to 0.91979, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 33s 459ms/step - loss: 0.8874 - accuracy: 0.6838 - val_loss: 0.9198 - val_accuracy: 0.6614 - lr: 1.0000e-07\n",
            "Epoch 48/50\n",
            " 3/72 [>.............................] - ETA: 34s - loss: 0.8391 - accuracy: 0.6927"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-d6da12673b49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(\n",
        "    train_df,\n",
        "    validation_data=valid_df,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69Juq8B28Ddd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "19Ds0JypUoNjrzDde_24N0mkCfrv6g3ff",
      "authorship_tag": "ABX9TyMgfLLzd2rFteMR2LXwUUoO",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}