{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19Ds0JypUoNjrzDde_24N0mkCfrv6g3ff",
      "authorship_tag": "ABX9TyMWZx3PtPaIxUWTkcFIIhjU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MorningStarTM/brain_cancer_detection/blob/main/Tumor_classification_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dthQn83Z2kPE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import shuffle\n",
        "from glob import glob\n",
        "from tensorflow.keras.layers import*\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import*\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parameters\n",
        "HEIGHT, WIDTH = 224, 224\n",
        "CHANNEL = 3\n",
        "num_class = 3\n",
        "batch_size = 64\n",
        "class_names = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]"
      ],
      "metadata": {
        "id": "T4teVOGM3Am1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Pipeline"
      ],
      "metadata": {
        "id": "HnnXioXJ3LOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path, split=0.1):\n",
        "    images = shuffle(glob(os.path.join(path, \"*\", \"*.jpg\")))\n",
        "    \n",
        "    #size of split \n",
        "    split_size = int(len(images) * split)\n",
        "\n",
        "    #split the data\n",
        "    train_data, valid_data = train_test_split(images, test_size=split_size, random_state=42)\n",
        "    train_data, test_data = train_test_split(train_data, test_size=split_size, random_state=42)\n",
        "\n",
        "    return train_data, valid_data, test_data "
      ],
      "metadata": {
        "id": "Ox2OTSKc3Jvb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#process the image\n",
        "def process_image(path):\n",
        "    #decode the path\n",
        "    path = path.decode()\n",
        "    #read image\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    #resize the image\n",
        "    image = cv2.resize(image, [224, 224])\n",
        "    #scale the image\n",
        "    image = image / 255.0\n",
        "    #change the data type of image\n",
        "    image = image.astype(np.float32)\n",
        "\n",
        "    #labeling the image\n",
        "    class_name = path.split(\"/\")[-2]\n",
        "    class_idx = class_names.index(class_name)\n",
        "    class_idx = np.array(class_idx, dtype=np.int32)\n",
        "\n",
        "    return image, class_idx"
      ],
      "metadata": {
        "id": "uZB1usmn3SKW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse(path):\n",
        "    image, labels = tf.numpy_function(process_image, [path], (tf.float32, tf.int32))\n",
        "    labels = tf.one_hot(labels, 4)\n",
        "    image.set_shape([224, 224, 3])\n",
        "    labels.set_shape(4)\n",
        "  \n",
        "    return image, labels"
      ],
      "metadata": {
        "id": "CyncemCa3Vld"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tensorflow dataset\n",
        "def tf_dataset(images, batch=8):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images))\n",
        "    dataset = dataset.map(parse)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(2)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "Cgt4wkoX3X_V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "QLg-_DiG3a88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#input layer\n",
        "inputs = Input(shape=(WIDTH, HEIGHT, CHANNEL))"
      ],
      "metadata": {
        "id": "dErEI4Hw3ZYl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convolutional layer\n",
        "conv_x = Conv2D(16, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(inputs)\n",
        "#conv_x = BatchNormalization()(conv_x)\n",
        "conv_x = MaxPooling2D((2,2), strides=(2,2))(conv_x)\n",
        "conv_x = Conv2D(16, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "\n",
        "\n",
        "conv_x = Conv2D(32, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "#conv_x = BatchNormalization()(conv_x)\n",
        "conv_x = MaxPooling2D((2,2), strides=(1,1))(conv_x)\n",
        "conv_x = Conv2D(32, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "\n",
        "conv_x = Conv2D(64, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "#conv_x = BatchNormalization()(conv_x)\n",
        "conv_x = MaxPooling2D((2,2), strides=(2,2))(conv_x)\n",
        "conv_x = Conv2D(64, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "\n",
        "conv_x = Conv2D(128, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "#conv_x = BatchNormalization()(conv_x)\n",
        "conv_x = MaxPooling2D((2,2), strides=(2,2))(conv_x)\n",
        "conv_x = Conv2D(128, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "\n",
        "conv_x = Conv2D(256, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "#conv_x = BatchNormalization()(conv_x)\n",
        "conv_x = MaxPooling2D((2,2), strides=(2,2))(conv_x)\n",
        "conv_x = Conv2D(256, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "\n",
        "conv_x = Conv2D(512, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "#conv_x = BatchNormalization()(conv_x)\n",
        "conv_x = MaxPooling2D((2,2), strides=(2,2))(conv_x)\n",
        "conv_x = Conv2D(512, (3,3), activation='relu', padding='same', strides=(1,1), kernel_initializer='he_normal')(conv_x)\n",
        "\n",
        "#flatting\n",
        "flatten = Flatten()(conv_x)\n",
        "conv_x = Dense(64, activation='relu')(flatten)\n",
        "con_x = Dropout(0.3)(conv_x)\n",
        "#adding Dense layer with number of class \n",
        "outputs = Dense(4, activation='softmax')(conv_x)"
      ],
      "metadata": {
        "id": "DKGGELmz3cPs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "tmz0l_yZ4CS9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10v50j244GQV",
        "outputId": "89545c4c-28a7-425b-ab4e-c89a6ba0de69"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 224, 224, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 112, 112, 16)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 112, 112, 16)      2320      \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 112, 112, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 111, 111, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 111, 111, 32)      9248      \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 111, 111, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 55, 55, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 55, 55, 64)        36928     \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 55, 55, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 27, 27, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 27, 27, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 27, 27, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 13, 13, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 13, 13, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 13, 13, 512)       1180160   \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 6, 6, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 18432)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                1179712   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,898,708\n",
            "Trainable params: 5,898,708\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-7), loss=\"categorical_crossentropy\", metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ZDtf0KTF4gQT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_file = \"/content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\"\n",
        "csv_file = \"/content/drive/MyDrive/Model CSV/tumor_classification.csv\""
      ],
      "metadata": {
        "id": "vzMUtv7n5aVF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    ModelCheckpoint(model_file, verbose=1, save_best_only=True),\n",
        "    CSVLogger(csv_file),\n",
        "    ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, min_lr=1e-7, verbose=1)\n",
        "]"
      ],
      "metadata": {
        "id": "Q_sCvQqz42Jl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/drive/MyDrive/DataSet/brain_cancer/Training\""
      ],
      "metadata": {
        "id": "aFBRdZoz5YWN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split the dataset\n",
        "x_train, x_valid, x_test = load_data(data_path)\n",
        "print(f\"Train:{len(x_train)} - Test:{len(x_test)} - Valid:{len(x_valid)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv-qzDGk7vAt",
        "outputId": "597e9710-52be-4282-c787-44a2171e2cbc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:4586 - Test:573 - Valid:573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensor dataset\n",
        "train_df = tf_dataset(x_train)\n",
        "test_df = tf_dataset(x_test)\n",
        "valid_df = tf_dataset(x_valid)"
      ],
      "metadata": {
        "id": "pB8mmzzP756G"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_df,\n",
        "    validation_data=valid_df,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-OobjVj7-pl",
        "outputId": "9ff4d63b-9862-422f-c220-fd4139f9aca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.4543 - accuracy: 0.2327\n",
            "Epoch 1: val_loss improved from inf to 1.40748, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 45s 502ms/step - loss: 1.4543 - accuracy: 0.2327 - val_loss: 1.4075 - val_accuracy: 0.2513 - lr: 1.0000e-07\n",
            "Epoch 2/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.3924 - accuracy: 0.2684\n",
            "Epoch 2: val_loss improved from 1.40748 to 1.36281, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 444ms/step - loss: 1.3924 - accuracy: 0.2684 - val_loss: 1.3628 - val_accuracy: 0.3264 - lr: 1.0000e-07\n",
            "Epoch 3/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.3532 - accuracy: 0.3879\n",
            "Epoch 3: val_loss improved from 1.36281 to 1.33423, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 447ms/step - loss: 1.3532 - accuracy: 0.3879 - val_loss: 1.3342 - val_accuracy: 0.4119 - lr: 1.0000e-07\n",
            "Epoch 4/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.3273 - accuracy: 0.4119\n",
            "Epoch 4: val_loss improved from 1.33423 to 1.31474, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 443ms/step - loss: 1.3273 - accuracy: 0.4119 - val_loss: 1.3147 - val_accuracy: 0.3857 - lr: 1.0000e-07\n",
            "Epoch 5/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.3089 - accuracy: 0.3918\n",
            "Epoch 5: val_loss improved from 1.31474 to 1.30026, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 442ms/step - loss: 1.3089 - accuracy: 0.3918 - val_loss: 1.3003 - val_accuracy: 0.3700 - lr: 1.0000e-07\n",
            "Epoch 6/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.2943 - accuracy: 0.3799\n",
            "Epoch 6: val_loss improved from 1.30026 to 1.28860, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 449ms/step - loss: 1.2943 - accuracy: 0.3799 - val_loss: 1.2886 - val_accuracy: 0.3735 - lr: 1.0000e-07\n",
            "Epoch 7/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.2820 - accuracy: 0.3827\n",
            "Epoch 7: val_loss improved from 1.28860 to 1.27856, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 439ms/step - loss: 1.2820 - accuracy: 0.3827 - val_loss: 1.2786 - val_accuracy: 0.3770 - lr: 1.0000e-07\n",
            "Epoch 8/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.2711 - accuracy: 0.3947\n",
            "Epoch 8: val_loss improved from 1.27856 to 1.26928, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 436ms/step - loss: 1.2711 - accuracy: 0.3947 - val_loss: 1.2693 - val_accuracy: 0.3909 - lr: 1.0000e-07\n",
            "Epoch 9/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.2609 - accuracy: 0.4080\n",
            "Epoch 9: val_loss improved from 1.26928 to 1.26034, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 438ms/step - loss: 1.2609 - accuracy: 0.4080 - val_loss: 1.2603 - val_accuracy: 0.3997 - lr: 1.0000e-07\n",
            "Epoch 10/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.2512 - accuracy: 0.4232\n",
            "Epoch 10: val_loss improved from 1.26034 to 1.25168, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 437ms/step - loss: 1.2512 - accuracy: 0.4232 - val_loss: 1.2517 - val_accuracy: 0.4101 - lr: 1.0000e-07\n",
            "Epoch 11/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.2418 - accuracy: 0.4429\n",
            "Epoch 11: val_loss improved from 1.25168 to 1.24322, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 443ms/step - loss: 1.2418 - accuracy: 0.4429 - val_loss: 1.2432 - val_accuracy: 0.4154 - lr: 1.0000e-07\n",
            "Epoch 12/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.2327 - accuracy: 0.4586\n",
            "Epoch 12: val_loss improved from 1.24322 to 1.23494, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 447ms/step - loss: 1.2327 - accuracy: 0.4586 - val_loss: 1.2349 - val_accuracy: 0.4258 - lr: 1.0000e-07\n",
            "Epoch 13/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.2238 - accuracy: 0.4751\n",
            "Epoch 13: val_loss improved from 1.23494 to 1.22682, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 442ms/step - loss: 1.2238 - accuracy: 0.4751 - val_loss: 1.2268 - val_accuracy: 0.4520 - lr: 1.0000e-07\n",
            "Epoch 14/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.2151 - accuracy: 0.4904\n",
            "Epoch 14: val_loss improved from 1.22682 to 1.21881, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 445ms/step - loss: 1.2151 - accuracy: 0.4904 - val_loss: 1.2188 - val_accuracy: 0.4729 - lr: 1.0000e-07\n",
            "Epoch 15/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.2066 - accuracy: 0.5063\n",
            "Epoch 15: val_loss improved from 1.21881 to 1.21084, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 439ms/step - loss: 1.2066 - accuracy: 0.5063 - val_loss: 1.2108 - val_accuracy: 0.4834 - lr: 1.0000e-07\n",
            "Epoch 16/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1981 - accuracy: 0.5150\n",
            "Epoch 16: val_loss improved from 1.21084 to 1.20293, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 436ms/step - loss: 1.1981 - accuracy: 0.5150 - val_loss: 1.2029 - val_accuracy: 0.5026 - lr: 1.0000e-07\n",
            "Epoch 17/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1897 - accuracy: 0.5262\n",
            "Epoch 17: val_loss improved from 1.20293 to 1.19508, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 437ms/step - loss: 1.1897 - accuracy: 0.5262 - val_loss: 1.1951 - val_accuracy: 0.5113 - lr: 1.0000e-07\n",
            "Epoch 18/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1813 - accuracy: 0.5364\n",
            "Epoch 18: val_loss improved from 1.19508 to 1.18725, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 438ms/step - loss: 1.1813 - accuracy: 0.5364 - val_loss: 1.1872 - val_accuracy: 0.5166 - lr: 1.0000e-07\n",
            "Epoch 19/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1730 - accuracy: 0.5443\n",
            "Epoch 19: val_loss improved from 1.18725 to 1.17952, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 449ms/step - loss: 1.1730 - accuracy: 0.5443 - val_loss: 1.1795 - val_accuracy: 0.5253 - lr: 1.0000e-07\n",
            "Epoch 20/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1648 - accuracy: 0.5539\n",
            "Epoch 20: val_loss improved from 1.17952 to 1.17193, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 439ms/step - loss: 1.1648 - accuracy: 0.5539 - val_loss: 1.1719 - val_accuracy: 0.5253 - lr: 1.0000e-07\n",
            "Epoch 21/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1568 - accuracy: 0.5619\n",
            "Epoch 21: val_loss improved from 1.17193 to 1.16448, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 437ms/step - loss: 1.1568 - accuracy: 0.5619 - val_loss: 1.1645 - val_accuracy: 0.5323 - lr: 1.0000e-07\n",
            "Epoch 22/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1489 - accuracy: 0.5680\n",
            "Epoch 22: val_loss improved from 1.16448 to 1.15709, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 31s 433ms/step - loss: 1.1489 - accuracy: 0.5680 - val_loss: 1.1571 - val_accuracy: 0.5393 - lr: 1.0000e-07\n",
            "Epoch 23/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1411 - accuracy: 0.5726\n",
            "Epoch 23: val_loss improved from 1.15709 to 1.14978, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 442ms/step - loss: 1.1411 - accuracy: 0.5726 - val_loss: 1.1498 - val_accuracy: 0.5515 - lr: 1.0000e-07\n",
            "Epoch 24/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1334 - accuracy: 0.5778\n",
            "Epoch 24: val_loss improved from 1.14978 to 1.14255, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 436ms/step - loss: 1.1334 - accuracy: 0.5778 - val_loss: 1.1426 - val_accuracy: 0.5532 - lr: 1.0000e-07\n",
            "Epoch 25/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1257 - accuracy: 0.5855\n",
            "Epoch 25: val_loss improved from 1.14255 to 1.13540, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 441ms/step - loss: 1.1257 - accuracy: 0.5855 - val_loss: 1.1354 - val_accuracy: 0.5602 - lr: 1.0000e-07\n",
            "Epoch 26/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1182 - accuracy: 0.5909\n",
            "Epoch 26: val_loss improved from 1.13540 to 1.12833, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 31s 433ms/step - loss: 1.1182 - accuracy: 0.5909 - val_loss: 1.1283 - val_accuracy: 0.5654 - lr: 1.0000e-07\n",
            "Epoch 27/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1108 - accuracy: 0.5944\n",
            "Epoch 27: val_loss improved from 1.12833 to 1.12135, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 31s 433ms/step - loss: 1.1108 - accuracy: 0.5944 - val_loss: 1.1213 - val_accuracy: 0.5672 - lr: 1.0000e-07\n",
            "Epoch 28/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.1034 - accuracy: 0.6005\n",
            "Epoch 28: val_loss improved from 1.12135 to 1.11445, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 436ms/step - loss: 1.1034 - accuracy: 0.6005 - val_loss: 1.1145 - val_accuracy: 0.5672 - lr: 1.0000e-07\n",
            "Epoch 29/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.0962 - accuracy: 0.6023\n",
            "Epoch 29: val_loss improved from 1.11445 to 1.10758, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 436ms/step - loss: 1.0962 - accuracy: 0.6023 - val_loss: 1.1076 - val_accuracy: 0.5707 - lr: 1.0000e-07\n",
            "Epoch 30/50\n",
            "72/72 [==============================] - ETA: 0s - loss: 1.0890 - accuracy: 0.6064\n",
            "Epoch 30: val_loss improved from 1.10758 to 1.10076, saving model to /content/drive/MyDrive/CNN_Models/tumor_classfication_1.h5\n",
            "72/72 [==============================] - 32s 444ms/step - loss: 1.0890 - accuracy: 0.6064 - val_loss: 1.1008 - val_accuracy: 0.5777 - lr: 1.0000e-07\n",
            "Epoch 31/50\n",
            "44/72 [=================>............] - ETA: 10s - loss: 1.0832 - accuracy: 0.6133"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "69Juq8B28Ddd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}